{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEE 609 Term Project - Data Download and Pre-processing Code\n",
    "## Adarsh Raghuram\n",
    "This study examines changes in sensitivity of corn yields to heat stress in the rainfed regions of the United States. Datasets used include climate renanlysis data from ERA5, annual county-level yield data from USDA and crop planting and harvesting dates from Sachs et al. (2010). Methods for obtaining and processing data in explained in the following sections. Unless indicated otherwise, the codes are written in R Programming Language Version 4.1.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading Shapefile from US Census Database\n",
    "I have used an older (2010) shapefile for mapping yields with counties, however, newer ones are availabe. The following link contains the archival and latest shapefiles - https://www2.census.gov/geo/tiger/GENZ2010/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp <- download.file('https://www2.census.gov/geo/tiger/GENZ2010/gz_2010_us_050_00_20m.zip', 'us_shp.zip')\n",
    "zipPath <- \"/downloads/us_shp.zip\" # Path for the zip file\n",
    "dir.create('/downloads/us_shp')\n",
    "out <- \"/downloads/us_shp\"\n",
    "unzip(zipPath,out) # Unzip the zipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Crop Planting and Harvesting Dates\n",
    "dates <- download.file('https://drive.google.com/file/d/1jVbKPigKbz9i6mwonza3Tv1Zzye_2QzT/view?usp=sharing', 'dates.zip')\n",
    "zipPath <- '/downloads/dates.zip'\n",
    "dir.create('planting_dates')\n",
    "out <- '/downlaods/planting_dates/maize_usa_crop_calendar.nc'\n",
    "unzip(zipPath, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Downloading and Processing Corn Yield Data from USDA Quickstats Database\n",
    "\n",
    "I accessed the USDA yield data directly from a web browser and the steps involved are described below:\n",
    "- Go to the USDA Quickstats database page at https://quickstats.nass.usda.gov/\n",
    "- Under the 'Select Commodity' section select the parameter mentioned for each category - Program: SURVEY -> Sector: CROPS -> Group: FIELD CROPS -> Commodity: CORN -> Data Item: CORN, GRAIN - YIELD, MEASURED IN BU/ACRE\n",
    "- Under the 'Select Location\" section select 'COUNTY' under Geographic Level\n",
    "- Under the 'Select Time' section select years from 1960 to 1974\n",
    "- After the data table is loaded click on 'spreadsheet' on the top right \n",
    "- Repeat the above steps with years 1975 to 1994 and again with years 1995 to 2020. This is necessary since not more than 50,000 records can be retrieved at once.\n",
    "\n",
    "Note that the API available for accessing USDA Quickstats data (https://quickstats.nass.usda.gov/api/) is basic and can only retrieve summary statistics of datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Mapping Yields with Counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv files\n",
    "df1 <- read.csv('Corn_1960-1974_yield_Bu_per_acre.csv')[,c(2,6,7,11,20)]\n",
    "df2 <- read.csv('Corn_1975-1994_yield_Bu_per_acre.csv')[,c(2,6,7,11,20)]\n",
    "df3 <- read.csv('Corn_1995-2020_yield_Bu_per_acre.csv')[,c(2,6,7,11,20)]\n",
    "\n",
    "# Merge csv files to create a continuous time series\n",
    "df <- rbind(df1,df2,df3)\n",
    "df <- df[!is.na(df$County.ANSI),]\n",
    "df$State.ANSI <- sprintf(\"%02d\", as.numeric(df$State.ANSI)) # to make '1' as '01' - this is to match with the state FIPS code in the shapefile\n",
    "df$County.ANSI <- sprintf(\"%03d\", as.numeric(df$County.ANSI)) # to make '1' as '001' - this is to match with the state FIPS code in the shapefile\n",
    "df$geoid <- paste0(df$State.ANSI,df$County.ANSI) # create a new column to merge with shapefile\n",
    "\n",
    "# Map yields with counties\n",
    "\n",
    "library(sf)\n",
    "library(raster)\n",
    "\n",
    "sp.df <- split.data.frame(df,df$Year) # split yield data into a list with years as indices\n",
    "\n",
    "st <- st_read('/downloads/gz_2010_us_050_00_20m.shp') # read shapefile\n",
    "st <- st[!(st$STATE %in% c('02','15','72')),] # to subset sf object without AK,HI and PU states\n",
    "\n",
    "\n",
    "for(i in 1:length(sp.df)){\n",
    "    yld_geo <- as.data.frame(sp.df[[i]][,c(5,6)])\n",
    "    colnames(yld_geo) <- c('yield','geoid')\n",
    "    match <- match(substr(st.df$GEO_ID,10,14),yld_geo$geoid)\n",
    "    \n",
    "    yield <- rep(NA, 3109)\n",
    "    for(j in 1:3109){\n",
    "        if(is.na(match[j])){\n",
    "            yield[j] <- NA\n",
    "        }else{yield[j] <- yld_geo$yield[match[j]]} # to write match values - for eg. if match[2] = 22, then yield[2] <- usda$Value[22]\n",
    "    }\n",
    "\n",
    "    yield <- gsub(',','',yield) #remove comma becasue as.numeric won't work with comma\n",
    "\n",
    "    yield.df <- as.data.frame(cbind(yield,st.df$GEO_ID))\n",
    "    colnames(yield.df) <- c(paste0(i+1959,'_yd'),'GEO_ID')\n",
    "    \n",
    "    yield.df[,1] <- as.numeric(yield.df[,1])\n",
    "    yield.df[,1] <- 67.251*yield.df[,1] # convert Bu/Acre to Kg/ha\n",
    "    \n",
    "    st <- merge(st,yield.df, by = 'GEO_ID')\n",
    "}\n",
    "\n",
    "# write a shapefile (analogus to geopanda dataframe)\n",
    "st_write(st, 'Corn_1960-2020_yield_kg_per_ha.shp', driver = \"ESRI Shapefile\") \n",
    "\n",
    "\n",
    "# Rasterize yield to 50 km gridded format and create a stack of all years\n",
    "# rasterizing to 50 km grids to match the resolution of data on planting and harvesting dates \n",
    "\n",
    "shp <- st_read('/downloads/Corn_1960-2020_yield_kg_per_ha.shp')\n",
    "ref <- st_read('/downloads/Corn_2010_hectares_harvested.shp')\n",
    "y <- raster(nrow = dim(shp)[1], ncol = dim(shp)[2])\n",
    "for(i in 1960:2020){\n",
    "    ras <- raster(res = c(0.5,0.5), extent(ref), crs = crs(ref))\n",
    "    field <- paste0('X',i,'_yd_x')\n",
    "    ras <- rasterize(shp, ras, field)\n",
    "    y <- addLayer(y,ras)\n",
    "    rm(ras)\n",
    "}\n",
    "\n",
    "saveRDS(y, '/downloads/corn_yield_stack_1960_2020.rds') # write raster stack as an RDS file - smaller fize size and faster processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Detrending Yield \n",
    "To account for time fixed effects, the yield data is detrended by removing the time trends and retaining anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to identify trends and get the slope and intercept for each pixel\n",
    "\n",
    "y <- readRDS('/downloads/corn_yield_stack_1960_2020.rds')\n",
    "yd <- as.array(y)\n",
    "\n",
    "dim(yd) # get dimensions of array\n",
    "\n",
    "slope <- raster(nrow = 50, ncol = 116) # 50 and 116 are dimensions of the array\n",
    "int <- raster(nrow = 50, ncol = 116)\n",
    "l <- 1:61 # time in years\n",
    "for(i in 1:50){\n",
    "    for(j in 1:116){\n",
    "            vector <- as.numeric(yd[i,j,])\n",
    "            vector[vector == 0] <- NA\n",
    "            if(all(is.na(vector))){\n",
    "                    slope[i,j] <-  NA\n",
    "                    int[i,j] <- NA\n",
    "            } else{\n",
    "            fit <- lm(vector~l)\n",
    "            slope[i,j] <-  fit$coefficients[2]\n",
    "            int[i,j] <- fit$coefficients[1]       \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# remove trends and write the detrended yields to a raster brick\n",
    "\n",
    "det <- array(numeric(), c(50,116,61))\n",
    "\n",
    "for(i in 1:50){\n",
    "    for(j in 1:116){\n",
    "        for(k in 1:61){\n",
    "            det[i,j,k] <- (yd[i,j,k] - (slope[i,j]*k + int[i,j]))\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "det.ras <- brick(det, xmn = extent(y)[1], xmx = extent(y)[2], ymn = extent(y)[3], ymx = extent(y)[4], crs = crs(y))\n",
    "saveRDS(det.ras, 'detrended_yield_stack_1960_2020.rds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Downloading and Processing ERA5 Reanalysis Data\n",
    "\n",
    "ERA5 data is hosted on the Climate Data Store (CDS) database, maintained by ECMWF. All data on this server can be accessed through a python-based API client. The 'cdsapi' package on python is necessary for accessing data. Documentation and tutorials can be accesed at https://cds.climate.copernicus.eu/api-how-to \n",
    "\n",
    "After creating an account and registering for API key, run the below python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading hourly maximum surface temperature through API\n",
    "\n",
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'netcdf',\n",
    "        'year': [\n",
    "            '1960', '1961', '1962',\n",
    "            '1963', '1964', '1965',\n",
    "            '1966', '1967', '1968',\n",
    "            '1969', '1970', '1971',\n",
    "        ],\n",
    "        'variable': 'maximum_2m_temperature_since_previous_post_processing',\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'day': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "            '13', '14', '15',\n",
    "            '16', '17', '18',\n",
    "            '19', '20', '21',\n",
    "            '22', '23', '24',\n",
    "            '25', '26', '27',\n",
    "            '28', '29', '30',\n",
    "            '31',\n",
    "        ],\n",
    "        'time': [\n",
    "            '00:00', '01:00', '02:00',\n",
    "            '03:00', '04:00', '05:00',\n",
    "            '06:00', '07:00', '08:00',\n",
    "            '09:00', '10:00', '11:00',\n",
    "            '12:00', '13:00', '14:00',\n",
    "            '15:00', '16:00', '17:00',\n",
    "            '18:00', '19:00', '20:00',\n",
    "            '21:00', '22:00', '23:00',\n",
    "        ],\n",
    "        'area': [\n",
    "            50, -126, 24,\n",
    "            -64,\n",
    "        ],\n",
    "    },\n",
    "    'tmax_hourly_1960.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a maximum of 120,000 records can be retrieved at once and also because yearly files are easier to calculate annual growing season KDD and GDD, re-run the above code by updating the 'year' section. This can also be done with a simple 'for' loop iterated over years. Once all data is downloaded for maximum temperature, repeat the above process for other variables by updating variable name in the 'variable' section, as listed below:\n",
    "\n",
    "- Minimum surface temperature: 'maximum_2m_temperature_since_previous_post_processing'\n",
    "- Soil moisture: 'volumetric_soil_water_layer_1'\n",
    "\n",
    "I used Climate Data Operators (CDO), a set of tools for processing and analyzing all forms of gridded data, for creating a complete timeseries from 1960 to 2020 for each variable, followed by calculation of daily averages from hourly values. Steps for installing and using CDO is available here - https://code.mpimet.mpg.de/projects/cdo/wiki/Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Processing Data in CDO\n",
    "\n",
    "Use the following CDO commands in a linux terminal for calculating daily average:\n",
    "\n",
    ">  cdo daymean  tmax_hourly_1960.nc  tmax_daily_1960.nc\n",
    "\n",
    ">  cdo daymean  tmin_hourly_1960.nc  tmin_daily_1960.nc\n",
    "\n",
    ">  cdo daymean  sm_hourly_1960.nc  sm_daily_1960.nc\n",
    "\n",
    "The above commands can be automated for all years in a bash script as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "\n",
    "for i in $(seq 1960 2020);\n",
    "do\n",
    "  screen -dmS \"$i\" cdo daymean tmax_hourly_$i.nc tmax_daily_$i.nc\n",
    "  sleep 2s\n",
    "done    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to regrid all netCDF files to 0.5 by 0.5 degrees to match the resolution of the planting and harvesting dates and yield data. For this, create a text file named 'grid.txt' and enter the below lines:\n",
    "\n",
    ">gridtype  = lonlat\n",
    "\n",
    ">gridsize  = 6448\n",
    "\n",
    ">xsize     = 124\n",
    "\n",
    ">ysize     = 52\n",
    "\n",
    ">xname     = longitude\n",
    "\n",
    ">xlongname = \"longitude\"\n",
    "\n",
    ">xunits    = \"degrees_east\"\n",
    "\n",
    ">yname     = latitude\n",
    "\n",
    ">ylongname = \"latitude\"\n",
    "\n",
    ">yunits    = \"degrees_north\"\n",
    "\n",
    ">xfirst    = -125.749992370605\n",
    "\n",
    ">xinc      = 0.5\n",
    "\n",
    ">yfirst    = 49.7500012715658\n",
    "\n",
    ">yinc      = -0.500000012466331\n",
    "\n",
    ">scanningMode = 64\n",
    "\n",
    "\n",
    "Finally, run the below cdo commands to complete regridding:\n",
    "\n",
    "> cdo remapbil,grid.txt tmax_daily_1960.nc tmax_daily_1960_50km.nc\n",
    "\n",
    "> cdo remapbil,grid.txt tmin_daily_1960.nc tmin_daily_1960_50km.nc\n",
    "\n",
    "> cdo remapbil,grid.txt sm_daily_1960.nc sm_daily_1960_50km.nc\n",
    "\n",
    "These commands can also be automated to run over all years using a bash script as shown above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Calculating Killing Degree Days (KDD) and Growing Degree Days (GDD)\n",
    "\n",
    "Growing season KDD and GDD is calculated over each pixel, using the planting and harvesting dates. Below is an R code for calculating and writing annual growing season KDD and GDD into netCDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate and write Growing Season KDD into netCDF files \n",
    "\n",
    "library(ncdf4) # for netCDF file handling\n",
    "\n",
    "nc <- nc_open('/downloads/maize_usa_crop_calendar.nc')\n",
    "\n",
    "# plantting and harvest dates - GROWING SEASON\n",
    "pl <- ncvar_get(ma, 'plant.start')\n",
    "hr <- ncvar_get(ma, 'harvest.end')\n",
    "\n",
    "for(i in 1960:2020){\n",
    "    nc <- nc_open(paste0('/downloads/tmax_daily_',i,'.nc'))\n",
    "    \n",
    "    lon.ar <- as.array(ncvar_get(nc, 'longitude'))\n",
    "    lat.ar <- as.array(ncvar_get(nc, 'latitude'))\n",
    "    \n",
    "    temp <- ncvar_get(nc, 'mx2t') # read the maximum temperature array\n",
    "    temp <- temp - 273.15     # convert temperature from Kelvin scale to degrees celcius\n",
    "    temp <- temp - 29         # definition of KDD\n",
    "    temp[temp < 0] <- 0\n",
    "    \n",
    "    kdd <- array(numeric(), c(124,52)) #dimension of the temperature array\n",
    "    \n",
    "    for(x in 1:124){\n",
    "    for(y in 1:52){\n",
    "        if(!is.na(pl[x,y])){\n",
    "            kdd[x,y] <- sum(temp[x,y,(pl[x,y]:hr[x,y])], na.rm = T)\n",
    "        } else{\n",
    "            kdd[x,y] <- NA\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ncfname <- paste0('/downloads/kdd_gs_corn_',i,'.nc') # growing season KDD\n",
    "    dname <- \"kdd\" \n",
    "\n",
    "    londim <- ncdim_def(\"lon\",\"degrees_east\",as.double(lon.ar)) \n",
    "    latdim <- ncdim_def(\"lat\",\"degrees_north\",as.double(lat.ar)) \n",
    "\n",
    "    #tunits <- 'hours since 31-12-2020 23:00:00 IST'\n",
    "    timedim <- ncdim_def(\"time\",'static',1)\n",
    "\n",
    "    # define variables\n",
    "    dlname <- \"Killing degree days\"\n",
    "    kdd_def <- ncvar_def(\"kdd\",\"deg_C_days\",list(londim,latdim,timedim),-999,dlname,prec=\"single\")\n",
    "    \n",
    "    ncout <- nc_create(ncfname,list(kdd_def),force_v4=TRUE)\n",
    "\n",
    "    # put variables\n",
    "    ncvar_put(ncout,kdd_def,kdd)\n",
    "    \n",
    "    nc_close(ncout)\n",
    "    nc_close(nc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate and write Growing Season GDD into netCDF files \n",
    "\n",
    "library(ncdf4)\n",
    "nc <- nc_open('/downloads/maize_usa_crop_calendar.nc')\n",
    "\n",
    "# plantting and harvest dates - GROWING SEASON\n",
    "pl <- ncvar_get(ma, 'plant.start')\n",
    "hr <- ncvar_get(ma, 'harvest.end')\n",
    "\n",
    "\n",
    "for(i in 1960:2020){\n",
    "    max <- nc_open(paste0('/downloads/tmax_daily_',i,'.nc'))\n",
    "    min <- nc_open(paste0('/downloads/tmin_daily_',i,'.nc'))\n",
    "    \n",
    "    lon.ar <- as.array(ncvar_get(max, 'longitude'))\n",
    "    lat.ar <- as.array(ncvar_get(max, 'latitude'))\n",
    "    \n",
    "    tmax <- ncvar_get(max, 'mx2t')\n",
    "    tmax <- tmax - 273.15\n",
    "    tmax[tmax > 30] <- 30\n",
    "    \n",
    "    tmin <- ncvar_get(min, 'mn2t')\n",
    "    tmin <- tmin - 273.15\n",
    "    tmin[tmin < 10] <- 10\n",
    "    \n",
    "    gdd <- ((tmax+tmin)/2 - 10) # Definition of GDD\n",
    "    \n",
    "    gdd.ar <- array(numeric(), c(124,52))\n",
    "    \n",
    "    for(x in 1:124){\n",
    "    for(y in 1:52){\n",
    "        if(!is.na(pl[x,y])){\n",
    "            gdd.ar[x,y] <- sum(gdd[x,y,(pl[x,y]:hr[x,y])], na.rm = T)\n",
    "        } else{\n",
    "            gdd.ar[x,y] <- NA\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ncfname <- paste0('/downloads/gdd_gs_corn_',i,'.nc') # growing season GDD\n",
    "    dname <- \"gdd\" \n",
    "\n",
    "    londim <- ncdim_def(\"lon\",\"degrees_east\",as.double(lon.ar)) \n",
    "    latdim <- ncdim_def(\"lat\",\"degrees_north\",as.double(lat.ar)) \n",
    "\n",
    "    #tunits <- 'hours since 31-12-2020 23:00:00 IST'\n",
    "    timedim <- ncdim_def(\"time\",'static',1)\n",
    "\n",
    "    # define variables\n",
    "    dlname <- \"Growing degree days\"\n",
    "    gdd_def <- ncvar_def(\"gdd\",\"deg_C_days\",list(londim,latdim,timedim),-999,dlname,prec=\"single\")\n",
    "    \n",
    "    ncout <- nc_create(ncfname,list(gdd_def),force_v4=TRUE)\n",
    "\n",
    "    # put variables\n",
    "    ncvar_put(ncout,gdd_def,gdd.ar)\n",
    "    \n",
    "    nc_close(ncout)\n",
    "    nc_close(max)\n",
    "    nc_close(min)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Calculate Growing Season Average Soil Moisture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to write out daily growing season soil moisture\n",
    "\n",
    "for(i in 1960:2020){\n",
    "    nc <- nc_open(paste0('/downloads/sm_daily_',i,'.nc'))\n",
    "    \n",
    "    lon.ar <- as.array(ncvar_get(nc, 'longitude'))\n",
    "    lat.ar <- as.array(ncvar_get(nc, 'latitude'))\n",
    "    \n",
    "    sm <- ncvar_get(nc, 'swvl1')\n",
    "        \n",
    "    kdd <- array(numeric(), c(124,52))\n",
    "    \n",
    "    for(x in 1:124){\n",
    "    for(y in 1:52){\n",
    "        if(!is.na(pl[x,y])){\n",
    "            kdd[x,y] <- mean(sm[x,y,(pl[x,y]:hr[x,y])], na.rm = T)\n",
    "        } else{\n",
    "            kdd[x,y] <- NA\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    ncfname <- paste0('/downloads/sm_corn_gs_mean_',i,'.nc') # growing season soil moisture\n",
    "    dname <- \"sm\"  \n",
    "    \n",
    "    londim <- ncdim_def(\"lon\",\"degrees_east\",as.double(lon.ar)) \n",
    "    latdim <- ncdim_def(\"lat\",\"degrees_north\",as.double(lat.ar)) \n",
    "\n",
    "    #tunits <- 'hours since 31-12-2020 23:00:00 IST'\n",
    "    timedim <- ncdim_def(\"time\",'static',1)\n",
    "\n",
    "    # define variables\n",
    "    dlname <- \"Growing Season Average Soil Moisture - Volumetric Soil Water(m^3/m^3)\"\n",
    "    sm_def <- ncvar_def(\"sm\",\"deg_C_days\",list(londim,latdim,timedim),-999,dlname,prec=\"single\")\n",
    "    \n",
    "    ncout <- nc_create(ncfname,list(sm_def),force_v4=TRUE)\n",
    "\n",
    "    # put variables\n",
    "    ncvar_put(ncout,sm_def,sm)\n",
    "    \n",
    "    nc_close(ncout)\n",
    "    nc_close(nc)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
